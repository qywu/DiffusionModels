{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87ec9ac-cb88-4908-9f66-3a9a396e1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from UNet import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9c047-805c-4a94-a60d-7ed2b8881b30",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c152c2-d2e5-4df0-a3e0-b4a5090f0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "batch_size = 128\n",
    "eval_batch_size = 256\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 10\n",
    "num_warmup_stesp = 500\n",
    "\n",
    "# diffusion model\n",
    "diffusion_steps = 1000\n",
    "beta_large = 0.02\n",
    "beta_small = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7c7fa-c6df-4db6-96c6-3b3accb14508",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14056262-da0c-43a0-8142-a67ac13debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "      torchvision.datasets.MNIST('/tmp/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize(32),\n",
    "                             ])),\n",
    "      batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "     torchvision.datasets.MNIST('/tmp/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize(32),\n",
    "                             ])),\n",
    "      batch_size=eval_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7488919e-7f19-44ac-a50f-aa4d3708cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = UNet(\n",
    "        input_channels=1,\n",
    "        input_height=32,\n",
    "        ch=64,\n",
    "        ch_mult=(1, 2, 2, 2),\n",
    "        num_res_blocks=1,\n",
    "        attn_resolutions=(16,),\n",
    "        resamp_with_conv=True,\n",
    "        dropout=0.,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6bc48a-c963-4597-820e-3995053ed6b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tests Model and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878fc1ee-40bf-42f8-955d-8e2ba0b5f7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    break\n",
    "    \n",
    "fig = plt.figure\n",
    "plt.imshow(batch[0][0].view(32,32), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d78b91-fa31-4fe4-888b-a0328864d170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = torch.randn(1, 1, 32, 32)\n",
    "t = torch.zeros(1)\n",
    "output = model(x_, t)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6584bf6e-332e-4e3f-99b8-bf9e55a8b382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parameters\n",
    "sum(p.numel() for p in model.parameters()) // 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74728582-7a3e-44a4-baa4-a9d7d8953c9e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fada49-72d8-4dd5-a56d-533c835a1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(imgs):\n",
    "    z_noise = torch.randn_like(imgs)\n",
    "    ts = torch.randint(1, diffusion_steps, (imgs.shape[0],), device=imgs.device)\n",
    "    a_sampled = alpha_bars[ts -1].view(-1, 1, 1, 1)\n",
    "    noised_imgs = torch.sqrt(a_sampled) * imgs + torch.sqrt(1 - a_sampled) * z_noise\n",
    "    return noised_imgs, ts, z_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e005bc-22f1-4b44-8871-a895a1ef1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficietns\n",
    "betas = torch.Tensor([beta_small + (t / diffusion_steps) * (beta_large - beta_small) for t in range(diffusion_steps)])\n",
    "alphas = 1 - betas\n",
    "alpha_bars = torch.cumprod(alphas, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2ac224-a978-422f-9bb4-5493e76dc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_stesp, num_training_steps=len(train_loader)*num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999d6778-9284-4009-b59b-df65759111f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send to device\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "betas = betas.to(device)\n",
    "alphas = alphas.to(device)\n",
    "alpha_bars = alpha_bars.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae64c641-94ed-4f18-b4de-72b19819f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf06312187d649d9ab8fbf866261212b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecf1fcae390405b9a0c60923f913d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation loss: 0.6288435459136963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef16b415e6e492da375f6248d3e89ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_205301/326532144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mndmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Too many dimensions: {ndim} > {ndmax}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    pbar = tqdm.auto.tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        noised_imgs, ts, z_noise = add_noise(imgs)\n",
    "        \n",
    "        e_hat = model(noised_imgs, ts)\n",
    "        \n",
    "        loss = (e_hat - z_noise).square().mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        with torch.random.fork_rng():\n",
    "            torch.random.manual_seed(123)\n",
    "            loss = 0\n",
    "            for batch in tqdm.auto.tqdm(test_loader):\n",
    "                imgs, labels = batch\n",
    "                imgs = imgs.to(device)\n",
    "\n",
    "                noised_imgs, ts, z_noise = add_noise(imgs)\n",
    "\n",
    "                e_hat = model(noised_imgs, ts)\n",
    "\n",
    "                loss += (e_hat - z_noise).square().mean()\n",
    "\n",
    "            loss /= len(test_loader)\n",
    "            print(f\"Epoch {epoch} Validation loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4e565-acb8-43bb-91c3-f6f35751a27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672928b9-9684-490b-bd4a-c965af82c92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f3407-727e-4a38-9519-c36c2037c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed6915-2df0-41b1-9bd2-cc66557bbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe0978-1db2-45fd-bdc0-e80d9a97e21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dfa79-082b-49e1-ab21-b98faaf1d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c75cd-69c7-4c90-8eef-cdcba97e8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet import get_sinusoidal_positional_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e25e9c-cf6b-49e0-8dc2-43028ea61755",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sinusoidal_positional_embedding(torch.LongTensor([0, 1, 2, 3, 4]), 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035ad62-1a9e-4eff-ae34-14af59407f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c42a98-6332-4810-847e-a3c70b41361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b85108-0166-41e6-a2e9-80427aa1b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cosine_schedule(T, s=0.008):\n",
    "    def f(t, T):\n",
    "        return (np.cos((t / T + s) / (1 + s) * np.pi / 2)) ** 2\n",
    "    \n",
    "    alphas = []\n",
    "    f0 = f(0, T)\n",
    "\n",
    "    for t in range(T + 1):\n",
    "        alphas.append(f(t, T) / f0)\n",
    "    \n",
    "    betas = []\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n",
    "    \n",
    "    return np.array(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455c754-ae94-4c6b-a831-fe602f56522c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659cf787-19a7-4bec-bd3c-ffc49b54640d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404257fc-640d-46c9-b8df-ea0c6991a08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95753069-f01d-49e4-aa8e-9ddbcc3c0738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177042ed-8f94-4342-a547-ae0954fbdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d1d8c-4373-4d71-8399-fa419ffe9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Corresponds to Algorithm 1 from (Ho et al., 2020).\n",
    "\"\"\"\n",
    "ts = torch.randint(0, self.t_range, [batch.shape[0]], device=self.device)\n",
    "noise_imgs = []\n",
    "epsilons = torch.randn(batch.shape, device=self.device)\n",
    "for i in range(len(ts)):\n",
    "    a_hat = self.alpha_bar(ts[i])\n",
    "    noise_imgs.append(\n",
    "        (math.sqrt(a_hat) * batch[i]) + (math.sqrt(1 - a_hat) * epsilons[i])\n",
    "    )\n",
    "noise_imgs = torch.stack(noise_imgs, dim=0)\n",
    "e_hat = self.forward(noise_imgs, ts.unsqueeze(-1).type(torch.float))\n",
    "loss = nn.functional.mse_loss(\n",
    "    e_hat.reshape(-1, self.in_size), epsilons.reshape(-1, self.in_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8522025-9f44-4bd6-aa12-33fa2719e243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fa39b-97ee-4f82-bae0-552cde058ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfe03e-2569-4936-bb3f-52d1936237cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba2c3a-fb1a-42f5-a346-0afc1e05079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca522a-0ce9-483c-8cd7-528c3582cf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a72290-ab7a-493b-b39c-5ee48fdb8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process samples and save as gif\n",
    "gen_samples = (gen_samples * 255).type(torch.uint8)\n",
    "gen_samples = gen_samples.reshape(-1, gif_shape[0], gif_shape[1], train_dataset.size, train_dataset.size, train_dataset.depth)\n",
    "\n",
    "def stack_samples(gen_samples, stack_dim):\n",
    "    gen_samples = list(torch.split(gen_samples, 1, dim=1))\n",
    "    for i in range(len(gen_samples)):\n",
    "        gen_samples[i] = gen_samples[i].squeeze(1)\n",
    "    return torch.cat(gen_samples, dim=stack_dim)\n",
    "\n",
    "gen_samples = stack_samples(gen_samples, 2)\n",
    "gen_samples = stack_samples(gen_samples, 2)\n",
    "\n",
    "imageio.mimsave(\n",
    "    f\"{trainer.logger.log_dir}/pred.gif\",\n",
    "    list(gen_samples),\n",
    "    fps=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
